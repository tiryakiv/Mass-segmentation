{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model5LHzc import *\n",
    "from data_1ch import *\n",
    "\n",
    "vid=\"v029\" #version id should match the file number \n",
    "# Ran on DellWS with GeForce RTX3060 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiryakiv\\miniconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 images belonging to 1 classes.\n",
      "Found 300 images belonging to 1 classes.\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8526 - acc: 0.9163 - dice_coef: 0.1474 - iou: 0.0853Found 52 images belonging to 1 classes.\n",
      "Found 52 images belonging to 1 classes.\n",
      "250/250 [==============================] - 95s 327ms/step - loss: 0.8526 - acc: 0.9163 - dice_coef: 0.1474 - iou: 0.0853 - val_loss: 0.8833 - val_acc: 0.8677 - val_dice_coef: 0.1167 - val_iou: 0.0681\n",
      "\n",
      "Epoch 00001: saving model to files05\\unet_mass_seg_v029.hdf5\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 83s 333ms/step - loss: 0.7519 - acc: 0.9655 - dice_coef: 0.2481 - iou: 0.1516 - val_loss: 0.7500 - val_acc: 0.9679 - val_dice_coef: 0.2500 - val_iou: 0.1551\n",
      "\n",
      "Epoch 00002: saving model to files05\\unet_mass_seg_v029.hdf5\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 81s 325ms/step - loss: 0.7325 - acc: 0.9708 - dice_coef: 0.2675 - iou: 0.1657 - val_loss: 0.7638 - val_acc: 0.9712 - val_dice_coef: 0.2362 - val_iou: 0.1477\n",
      "\n",
      "Epoch 00003: saving model to files05\\unet_mass_seg_v029.hdf5\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 83s 334ms/step - loss: 0.7126 - acc: 0.9722 - dice_coef: 0.2874 - iou: 0.1789 - val_loss: 0.7628 - val_acc: 0.9687 - val_dice_coef: 0.2372 - val_iou: 0.1472\n",
      "\n",
      "Epoch 00004: saving model to files05\\unet_mass_seg_v029.hdf5\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 82s 328ms/step - loss: 0.7003 - acc: 0.9717 - dice_coef: 0.2997 - iou: 0.1891 - val_loss: 0.7384 - val_acc: 0.9634 - val_dice_coef: 0.2616 - val_iou: 0.1613\n",
      "\n",
      "Epoch 00005: saving model to files05\\unet_mass_seg_v029.hdf5\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 81s 324ms/step - loss: 0.7089 - acc: 0.9721 - dice_coef: 0.2911 - iou: 0.1840 - val_loss: 0.7395 - val_acc: 0.9700 - val_dice_coef: 0.2605 - val_iou: 0.1610\n",
      "\n",
      "Epoch 00006: saving model to files05\\unet_mass_seg_v029.hdf5\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 80s 319ms/step - loss: 0.7069 - acc: 0.9723 - dice_coef: 0.2931 - iou: 0.1850 - val_loss: 0.7291 - val_acc: 0.9663 - val_dice_coef: 0.2709 - val_iou: 0.1702\n",
      "\n",
      "Epoch 00007: saving model to files05\\unet_mass_seg_v029.hdf5\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 84s 337ms/step - loss: 0.7030 - acc: 0.9719 - dice_coef: 0.2970 - iou: 0.1900 - val_loss: 0.7973 - val_acc: 0.9776 - val_dice_coef: 0.2027 - val_iou: 0.1262\n",
      "\n",
      "Epoch 00008: saving model to files05\\unet_mass_seg_v029.hdf5\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 81s 322ms/step - loss: 0.6838 - acc: 0.9744 - dice_coef: 0.3162 - iou: 0.2024 - val_loss: 0.7675 - val_acc: 0.9743 - val_dice_coef: 0.2325 - val_iou: 0.1466\n",
      "\n",
      "Epoch 00009: saving model to files05\\unet_mass_seg_v029.hdf5\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 81s 323ms/step - loss: 0.6935 - acc: 0.9732 - dice_coef: 0.3065 - iou: 0.1946 - val_loss: 0.7998 - val_acc: 0.9763 - val_dice_coef: 0.2002 - val_iou: 0.1261\n",
      "\n",
      "Epoch 00010: saving model to files05\\unet_mass_seg_v029.hdf5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 82s 329ms/step - loss: 0.6694 - acc: 0.9755 - dice_coef: 0.3306 - iou: 0.2134 - val_loss: 0.8191 - val_acc: 0.9766 - val_dice_coef: 0.1809 - val_iou: 0.1092\n",
      "\n",
      "Epoch 00011: saving model to files05\\unet_mass_seg_v029.hdf5\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 79s 316ms/step - loss: 0.6639 - acc: 0.9769 - dice_coef: 0.3361 - iou: 0.2201 - val_loss: 0.7377 - val_acc: 0.9815 - val_dice_coef: 0.2623 - val_iou: 0.1693\n",
      "\n",
      "Epoch 00012: saving model to files05\\unet_mass_seg_v029.hdf5\n",
      "Epoch 00012: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e9070ccd30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "\n",
    "#Data augmentation\n",
    "data_gen_args = dict(rotation_range=90,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    fill_mode='wrap')\n",
    "\n",
    "# SETTINGS ***\n",
    "batch_size=3\n",
    "learning_rate=1e-3\n",
    "\n",
    "train_gen = trainGenerator(batch_size,'mass_seg_05/train05','mass_seg','mass_seg_labels',data_gen_args,save_to_dir = None)\n",
    "valid_gen = trainGenerator(batch_size,'mass_seg_05/valid05','mass_seg','mass_seg_labels',data_gen_args,save_to_dir = None)\n",
    "\n",
    "# 300 images are used for training, 52 images for validating, and 60 images for testing\n",
    "train_steps = 300//batch_size\n",
    "valid_steps = 52//batch_size\n",
    "\n",
    "# SETTINGS ***\n",
    "loss=dice_loss\n",
    "steps_per_epoch=2.5*train_steps\n",
    "num_epochs=100\n",
    "num_top_filter=24\n",
    "\n",
    "model = unet(learning_rate, loss, num_top_filter)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate)\n",
    "metrics = [\"acc\", dice_coef, iou]\n",
    "model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "\n",
    "callbacks = [\n",
    "             ModelCheckpoint('files05/unet_mass_seg_'+vid+'.hdf5', verbose=1, save_best_model=True),\n",
    "             ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-8),\n",
    "             CSVLogger(\"files05/data_\"+vid+\".csv\"),\n",
    "             EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n",
    "            ]\n",
    "\n",
    "model.fit_generator(train_gen, validation_data=valid_gen, steps_per_epoch=steps_per_epoch, validation_steps=valid_steps, \n",
    "                    epochs=num_epochs, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate your model and save predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiryakiv\\miniconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 5s 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\0_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\1_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\3_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\4_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\9_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\12_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\14_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\16_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\18_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\19_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\24_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\29_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\30_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\35_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\36_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\37_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\38_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\39_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\42_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\43_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\44_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\45_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\46_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:125: UserWarning: mass_seg_05/valid05/pred\\47_predict_v029.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n"
     ]
    }
   ],
   "source": [
    "validGene = testGenerator(\"mass_seg_05/valid05/pred\")\n",
    "model.load_weights(\"files05/unet_mass_seg_\"+vid+\".hdf5\")\n",
    "results = model.predict_generator(validGene,52,verbose=1)\n",
    "saveResult(\"mass_seg_05/valid05/pred\",results,vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-latest",
   "language": "python",
   "name": "tf-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
