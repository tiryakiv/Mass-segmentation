{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelUnetVGG16 import *\n",
    "from data import *\n",
    "\n",
    "vid=\"v026\" #version id should match the file number \n",
    "# Ran on DellWS with GeForce RTX3060 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiryakiv\\miniconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 images belonging to 1 classes.\n",
      "Found 300 images belonging to 1 classes.\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - ETA: 0s - loss: 0.8324 - acc: 0.9244 - dice_coef: 0.1676 - iou: 0.0991Found 52 images belonging to 1 classes.\n",
      "Found 52 images belonging to 1 classes.\n",
      "450/450 [==============================] - 243s 488ms/step - loss: 0.8324 - acc: 0.9244 - dice_coef: 0.1676 - iou: 0.0991 - val_loss: 0.9146 - val_acc: 0.9744 - val_dice_coef: 0.0854 - val_iou: 0.0464\n",
      "\n",
      "Epoch 00001: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 223s 496ms/step - loss: 0.7409 - acc: 0.9668 - dice_coef: 0.2591 - iou: 0.1600 - val_loss: 0.8496 - val_acc: 0.9795 - val_dice_coef: 0.1504 - val_iou: 0.0899\n",
      "\n",
      "Epoch 00002: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 219s 487ms/step - loss: 0.6804 - acc: 0.9734 - dice_coef: 0.3196 - iou: 0.2071 - val_loss: 0.7119 - val_acc: 0.9807 - val_dice_coef: 0.2881 - val_iou: 0.1976\n",
      "\n",
      "Epoch 00003: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 219s 486ms/step - loss: 0.6419 - acc: 0.9764 - dice_coef: 0.3581 - iou: 0.2407 - val_loss: 0.9215 - val_acc: 0.9786 - val_dice_coef: 0.0785 - val_iou: 0.0487\n",
      "\n",
      "Epoch 00004: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 219s 486ms/step - loss: 0.6340 - acc: 0.9767 - dice_coef: 0.3660 - iou: 0.2482 - val_loss: 0.6413 - val_acc: 0.9765 - val_dice_coef: 0.3587 - val_iou: 0.2444\n",
      "\n",
      "Epoch 00005: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 218s 485ms/step - loss: 0.5980 - acc: 0.9799 - dice_coef: 0.4020 - iou: 0.2759 - val_loss: 0.7050 - val_acc: 0.9787 - val_dice_coef: 0.2950 - val_iou: 0.2008\n",
      "\n",
      "Epoch 00006: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 217s 482ms/step - loss: 0.5805 - acc: 0.9803 - dice_coef: 0.4195 - iou: 0.2903 - val_loss: 0.7006 - val_acc: 0.9821 - val_dice_coef: 0.2994 - val_iou: 0.2014\n",
      "\n",
      "Epoch 00007: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 218s 485ms/step - loss: 0.5712 - acc: 0.9804 - dice_coef: 0.4288 - iou: 0.3005 - val_loss: 0.5869 - val_acc: 0.9769 - val_dice_coef: 0.4131 - val_iou: 0.2938\n",
      "\n",
      "Epoch 00008: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 219s 487ms/step - loss: 0.5665 - acc: 0.9805 - dice_coef: 0.4335 - iou: 0.3050 - val_loss: 0.8560 - val_acc: 0.9872 - val_dice_coef: 0.1440 - val_iou: 0.0994\n",
      "\n",
      "Epoch 00009: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 219s 488ms/step - loss: 0.5573 - acc: 0.9812 - dice_coef: 0.4427 - iou: 0.3141 - val_loss: 0.5530 - val_acc: 0.9693 - val_dice_coef: 0.4470 - val_iou: 0.3151\n",
      "\n",
      "Epoch 00010: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 218s 485ms/step - loss: 0.5609 - acc: 0.9814 - dice_coef: 0.4391 - iou: 0.3092 - val_loss: 0.7025 - val_acc: 0.9836 - val_dice_coef: 0.2975 - val_iou: 0.2127\n",
      "\n",
      "Epoch 00011: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 220s 488ms/step - loss: 0.5471 - acc: 0.9823 - dice_coef: 0.4529 - iou: 0.3229 - val_loss: 0.6257 - val_acc: 0.9791 - val_dice_coef: 0.3743 - val_iou: 0.2591\n",
      "\n",
      "Epoch 00012: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 219s 486ms/step - loss: 0.5501 - acc: 0.9812 - dice_coef: 0.4499 - iou: 0.3181 - val_loss: 0.6776 - val_acc: 0.9803 - val_dice_coef: 0.3224 - val_iou: 0.2329\n",
      "\n",
      "Epoch 00013: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 219s 487ms/step - loss: 0.5085 - acc: 0.9835 - dice_coef: 0.4915 - iou: 0.3609 - val_loss: 0.6462 - val_acc: 0.9743 - val_dice_coef: 0.3538 - val_iou: 0.2623\n",
      "\n",
      "Epoch 00014: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 218s 484ms/step - loss: 0.4885 - acc: 0.9834 - dice_coef: 0.5115 - iou: 0.3777 - val_loss: 0.6040 - val_acc: 0.9830 - val_dice_coef: 0.3960 - val_iou: 0.2852\n",
      "\n",
      "Epoch 00015: saving model to files05\\unet_mass_seg_v026.hdf5\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c74ffa0ee0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "\n",
    "#Data augmentation\n",
    "data_gen_args = dict(rotation_range=90,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    fill_mode='wrap')\n",
    "\n",
    "# SETTINGS ***\n",
    "batch_size=2\n",
    "learning_rate=1e-4\n",
    "\n",
    "train_gen = trainGenerator(batch_size,'mass_seg_05/train05','mass_seg','mass_seg_labels',data_gen_args,save_to_dir = None)\n",
    "valid_gen = trainGenerator(batch_size,'mass_seg_05/valid05','mass_seg','mass_seg_labels',data_gen_args,save_to_dir = None)\n",
    "\n",
    "# 300 images are used for training, 52 images for validating, and 60 images for testing\n",
    "train_steps = 300//batch_size\n",
    "valid_steps = 52//batch_size\n",
    "\n",
    "# SETTINGS ***\n",
    "loss=dice_loss\n",
    "steps_per_epoch=3*train_steps\n",
    "num_epochs=100\n",
    "#num_top_filter=16\n",
    "\n",
    "model = build_vgg16_unet()\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate)\n",
    "metrics = [\"acc\", dice_coef, iou]\n",
    "model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "\n",
    "callbacks = [\n",
    "             ModelCheckpoint('files05/unet_mass_seg_'+vid+'.hdf5', verbose=1, save_best_model=True),\n",
    "             ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-8),\n",
    "             CSVLogger(\"files05/data_\"+vid+\".csv\"),\n",
    "             EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n",
    "            ]\n",
    "\n",
    "model.fit_generator(train_gen, validation_data=valid_gen, steps_per_epoch=steps_per_epoch, validation_steps=valid_steps, \n",
    "                    epochs=num_epochs, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate your model and save predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiryakiv\\miniconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 23s 360ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\0_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\1_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\3_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\7_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\12_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\14_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\15_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\16_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\18_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\19_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\25_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\28_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\29_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\30_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\32_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\35_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\36_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\39_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\40_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\41_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\43_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\44_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\45_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\46_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\47_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_05/valid05/pred\\50_predict_v026.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n"
     ]
    }
   ],
   "source": [
    "validGene = testGenerator(\"mass_seg_05/valid05/pred\")\n",
    "model.load_weights(\"files05/unet_mass_seg_\"+vid+\".hdf5\")\n",
    "results = model.predict_generator(validGene,52,verbose=1)\n",
    "saveResult(\"mass_seg_05/valid05/pred\",results,vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-latest",
   "language": "python",
   "name": "tf-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
