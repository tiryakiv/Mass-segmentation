{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model5LHzc import *\n",
    "from data_1ch import *\n",
    "import os, os.path\n",
    "\n",
    "vid=\"v001_5\" #version id should match the file number. Last number shows the cross-validation fold number\n",
    "# Ran on DellWS with GeForce RTX3060 GPU\n",
    "\n",
    "# Count the number of train and valid files\n",
    "train_dir = 'mg_seg_04/train0'+vid[-1]+'/mg_seg'\n",
    "train_count=len([name for name in os.listdir(train_dir) if os.path.isfile(os.path.join(train_dir, name))])\n",
    "\n",
    "valid_dir = 'mg_seg_04/valid0'+vid[-1]+'/mg_seg'\n",
    "valid_count=len([name for name in os.listdir(valid_dir) if os.path.isfile(os.path.join(valid_dir, name))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiryakiv\\miniconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 283 images belonging to 1 classes.\n",
      "Found 283 images belonging to 1 classes.\n",
      "Epoch 1/100\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0858 - acc: 0.9554 - dice_coef: 0.9144 - iou: 0.8492Found 69 images belonging to 1 classes.\n",
      "Found 69 images belonging to 1 classes.\n",
      "282/282 [==============================] - 229s 741ms/step - loss: 0.0858 - acc: 0.9554 - dice_coef: 0.9144 - iou: 0.8492 - val_loss: 0.3325 - val_acc: 0.5113 - val_dice_coef: 0.6675 - val_iou: 0.5088\n",
      "\n",
      "Epoch 00001: saving model to files_xval\\unet_mg_seg_v001_5.hdf5\n",
      "Epoch 2/100\n",
      "282/282 [==============================] - 189s 670ms/step - loss: 0.0357 - acc: 0.9710 - dice_coef: 0.9642 - iou: 0.9316 - val_loss: 0.0646 - val_acc: 0.9360 - val_dice_coef: 0.9354 - val_iou: 0.8825\n",
      "\n",
      "Epoch 00002: saving model to files_xval\\unet_mg_seg_v001_5.hdf5\n",
      "Epoch 3/100\n",
      "282/282 [==============================] - 184s 653ms/step - loss: 0.0303 - acc: 0.9729 - dice_coef: 0.9694 - iou: 0.9415 - val_loss: 0.0359 - val_acc: 0.9649 - val_dice_coef: 0.9641 - val_iou: 0.9326\n",
      "\n",
      "Epoch 00003: saving model to files_xval\\unet_mg_seg_v001_5.hdf5\n",
      "Epoch 4/100\n",
      "282/282 [==============================] - 188s 669ms/step - loss: 0.0298 - acc: 0.9720 - dice_coef: 0.9699 - iou: 0.9420 - val_loss: 0.0380 - val_acc: 0.9667 - val_dice_coef: 0.9620 - val_iou: 0.9325\n",
      "\n",
      "Epoch 00004: saving model to files_xval\\unet_mg_seg_v001_5.hdf5\n",
      "Epoch 5/100\n",
      "282/282 [==============================] - 192s 681ms/step - loss: 0.0265 - acc: 0.9749 - dice_coef: 0.9733 - iou: 0.9484 - val_loss: 0.0280 - val_acc: 0.9706 - val_dice_coef: 0.9720 - val_iou: 0.9474\n",
      "\n",
      "Epoch 00005: saving model to files_xval\\unet_mg_seg_v001_5.hdf5\n",
      "Epoch 6/100\n",
      "282/282 [==============================] - 191s 679ms/step - loss: 0.0266 - acc: 0.9750 - dice_coef: 0.9735 - iou: 0.9492 - val_loss: 0.0398 - val_acc: 0.9610 - val_dice_coef: 0.9602 - val_iou: 0.9257\n",
      "\n",
      "Epoch 00006: saving model to files_xval\\unet_mg_seg_v001_5.hdf5\n",
      "Epoch 7/100\n",
      "282/282 [==============================] - 184s 655ms/step - loss: 0.0243 - acc: 0.9768 - dice_coef: 0.9756 - iou: 0.9529 - val_loss: 0.0311 - val_acc: 0.9719 - val_dice_coef: 0.9689 - val_iou: 0.9415\n",
      "\n",
      "Epoch 00007: saving model to files_xval\\unet_mg_seg_v001_5.hdf5\n",
      "Epoch 8/100\n",
      "282/282 [==============================] - 183s 651ms/step - loss: 0.0251 - acc: 0.9761 - dice_coef: 0.9750 - iou: 0.9518 - val_loss: 0.0284 - val_acc: 0.9704 - val_dice_coef: 0.9716 - val_iou: 0.9453\n",
      "\n",
      "Epoch 00008: saving model to files_xval\\unet_mg_seg_v001_5.hdf5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/100\n",
      "282/282 [==============================] - 191s 679ms/step - loss: 0.0227 - acc: 0.9784 - dice_coef: 0.9772 - iou: 0.9557 - val_loss: 0.0253 - val_acc: 0.9761 - val_dice_coef: 0.9747 - val_iou: 0.9515\n",
      "\n",
      "Epoch 00009: saving model to files_xval\\unet_mg_seg_v001_5.hdf5\n",
      "Epoch 10/100\n",
      "282/282 [==============================] - 191s 679ms/step - loss: 0.0213 - acc: 0.9795 - dice_coef: 0.9787 - iou: 0.9584 - val_loss: 0.0291 - val_acc: 0.9700 - val_dice_coef: 0.9709 - val_iou: 0.9449\n",
      "\n",
      "Epoch 00010: saving model to files_xval\\unet_mg_seg_v001_5.hdf5\n",
      "Epoch 11/100\n",
      "282/282 [==============================] - 191s 678ms/step - loss: 0.0224 - acc: 0.9786 - dice_coef: 0.9776 - iou: 0.9566 - val_loss: 0.0341 - val_acc: 0.9663 - val_dice_coef: 0.9659 - val_iou: 0.9401\n",
      "\n",
      "Epoch 00011: saving model to files_xval\\unet_mg_seg_v001_5.hdf5\n",
      "Epoch 12/100\n",
      "282/282 [==============================] - 191s 680ms/step - loss: 0.0226 - acc: 0.9785 - dice_coef: 0.9774 - iou: 0.9562 - val_loss: 0.0290 - val_acc: 0.9705 - val_dice_coef: 0.9710 - val_iou: 0.9448\n",
      "\n",
      "Epoch 00012: saving model to files_xval\\unet_mg_seg_v001_5.hdf5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 13/100\n",
      "282/282 [==============================] - 188s 668ms/step - loss: 0.0235 - acc: 0.9777 - dice_coef: 0.9765 - iou: 0.9550 - val_loss: 0.0294 - val_acc: 0.9706 - val_dice_coef: 0.9706 - val_iou: 0.9473\n",
      "\n",
      "Epoch 00013: saving model to files_xval\\unet_mg_seg_v001_5.hdf5\n",
      "Epoch 14/100\n",
      "282/282 [==============================] - 191s 680ms/step - loss: 0.0218 - acc: 0.9793 - dice_coef: 0.9782 - iou: 0.9577 - val_loss: 0.0314 - val_acc: 0.9717 - val_dice_coef: 0.9686 - val_iou: 0.9420\n",
      "\n",
      "Epoch 00014: saving model to files_xval\\unet_mg_seg_v001_5.hdf5\n",
      "Epoch 00014: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c70a880700>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "\n",
    "#Data augmentation\n",
    "data_gen_args = dict(rotation_range=45,\n",
    "                    width_shift_range=0.1,\n",
    "                    height_shift_range=0.1,\n",
    "                    shear_range=0.1,\n",
    "                    zoom_range=0.1,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    fill_mode='wrap')\n",
    "\n",
    "# SETTINGS ***\n",
    "batch_size=3\n",
    "learning_rate=1e-3\n",
    "\n",
    "train_gen = trainGenerator(batch_size,'mg_seg_04/train0'+vid[-1],'mg_seg','mg_seg_labels',data_gen_args,save_to_dir = None)\n",
    "valid_gen = trainGenerator(batch_size,'mg_seg_04/valid0'+vid[-1],'mg_seg','mg_seg_labels',data_gen_args,save_to_dir = None)\n",
    "\n",
    "# 300 images are used for training, 52 images for validating, and 60 images for testing\n",
    "train_steps = train_count//batch_size\n",
    "valid_steps = valid_count//batch_size\n",
    "\n",
    "# SETTINGS ***\n",
    "loss=dice_loss\n",
    "steps_per_epoch=3*train_steps\n",
    "num_epochs=100\n",
    "\n",
    "model = unet(learning_rate, loss)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate)\n",
    "metrics = [\"acc\", dice_coef, iou]\n",
    "model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "\n",
    "callbacks = [\n",
    "             ModelCheckpoint('files_xval/unet_mg_seg_'+vid+'.hdf5', verbose=1, save_best_model=True),\n",
    "             ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-8),\n",
    "             CSVLogger(\"files_xval/data_\"+vid+\".csv\"),\n",
    "             EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n",
    "            ]\n",
    "\n",
    "model.fit_generator(train_gen, validation_data=valid_gen, steps_per_epoch=steps_per_epoch, validation_steps=valid_steps, \n",
    "                    epochs=num_epochs, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate your model and save predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 8s 123ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\research\\breastCancer\\mass_seg\\codes\\data_1ch.py:104: UserWarning: mg_seg_04/valid01/pred\\62_predict_v001.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n"
     ]
    }
   ],
   "source": [
    "validGene = testGenerator(\"mg_seg_04/valid0\"+vid[-1]+\"/pred\")\n",
    "model.load_weights(\"files_xval/unet_mg_seg_\"+vid+\".hdf5\")\n",
    "results = model.predict_generator(validGene,valid_count,verbose=1)\n",
    "saveResult(\"mg_seg_04/valid0\"+vid[-1]+\"/pred\",results,vid[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrainGene = testGenerator(\"mg_seg_03/train03/pred\")\\nmodel.load_weights(\"files/unet_mg_seg_\"+vid+\".hdf5\")\\nresults = model.predict_generator(trainGene,300,verbose=1)\\nsaveResult(\"mg_seg_03/train03/pred\",results,vid)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "trainGene = testGenerator(\"mg_seg_03/train03/pred\")\n",
    "model.load_weights(\"files/unet_mg_seg_\"+vid+\".hdf5\")\n",
    "results = model.predict_generator(trainGene,300,verbose=1)\n",
    "saveResult(\"mg_seg_03/train03/pred\",results,vid)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntestGene = testGenerator(\"mg_seg_03/test03/pred\")\\nmodel.load_weights(\"files/unet_mg_seg_\"+vid+\".hdf5\")\\nresults = model.predict_generator(testGene,60,verbose=1)\\nsaveResult(\"mg_seg_03/test03/pred\",results,vid)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "testGene = testGenerator(\"mg_seg_03/test03/pred\")\n",
    "model.load_weights(\"files/unet_mg_seg_\"+vid+\".hdf5\")\n",
    "results = model.predict_generator(testGene,60,verbose=1)\n",
    "saveResult(\"mg_seg_03/test03/pred\",results,vid)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
