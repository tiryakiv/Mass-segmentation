{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelUnetResnet50 import *\n",
    "from data import *\n",
    "import os, os.path\n",
    "\n",
    "vid=\"v009_5\" #version id should match the file number. Last number shows the cross-validation fold number\n",
    "# Ran on DellWS with GeForce RTX3060 GPU\n",
    "\n",
    "# Count the number of train and valid files\n",
    "train_dir = 'mass_seg_08/train0'+vid[-1]+'/mg'\n",
    "train_count=len([name for name in os.listdir(train_dir) if os.path.isfile(os.path.join(train_dir, name))])\n",
    "\n",
    "valid_dir = 'mass_seg_08/valid0'+vid[-1]+'/mg'\n",
    "valid_count=len([name for name in os.listdir(valid_dir) if os.path.isfile(os.path.join(valid_dir, name))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 283 images belonging to 1 classes.\n",
      "Found 283 images belonging to 1 classes.\n",
      "Epoch 1/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.8514 - acc: 0.9141 - dice_coef: 0.1485 - iou: 0.0855Found 69 images belonging to 1 classes.\n",
      "Found 69 images belonging to 1 classes.\n",
      "\n",
      "Epoch 1: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 349s 770ms/step - loss: 0.8514 - acc: 0.9141 - dice_coef: 0.1485 - iou: 0.0855 - val_loss: 0.9632 - val_acc: 0.9817 - val_dice_coef: 0.0368 - val_iou: 0.0189 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.7594 - acc: 0.9680 - dice_coef: 0.2402 - iou: 0.1449\n",
      "Epoch 2: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 242s 685ms/step - loss: 0.7594 - acc: 0.9680 - dice_coef: 0.2402 - iou: 0.1449 - val_loss: 0.9645 - val_acc: 0.9814 - val_dice_coef: 0.0355 - val_iou: 0.0184 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.6888 - acc: 0.9746 - dice_coef: 0.3119 - iou: 0.1988\n",
      "Epoch 3: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 241s 683ms/step - loss: 0.6888 - acc: 0.9746 - dice_coef: 0.3119 - iou: 0.1988 - val_loss: 0.7918 - val_acc: 0.9827 - val_dice_coef: 0.2082 - val_iou: 0.1252 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.6156 - acc: 0.9780 - dice_coef: 0.3844 - iou: 0.2584\n",
      "Epoch 4: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 242s 686ms/step - loss: 0.6156 - acc: 0.9780 - dice_coef: 0.3844 - iou: 0.2584 - val_loss: 0.5895 - val_acc: 0.9840 - val_dice_coef: 0.4105 - val_iou: 0.2765 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.5836 - acc: 0.9807 - dice_coef: 0.4165 - iou: 0.2868\n",
      "Epoch 5: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 241s 685ms/step - loss: 0.5836 - acc: 0.9807 - dice_coef: 0.4165 - iou: 0.2868 - val_loss: 0.6687 - val_acc: 0.9846 - val_dice_coef: 0.3313 - val_iou: 0.2287 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.5774 - acc: 0.9803 - dice_coef: 0.4228 - iou: 0.2963\n",
      "Epoch 6: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 244s 690ms/step - loss: 0.5774 - acc: 0.9803 - dice_coef: 0.4228 - iou: 0.2963 - val_loss: 0.7364 - val_acc: 0.9855 - val_dice_coef: 0.2636 - val_iou: 0.1789 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.5211 - acc: 0.9832 - dice_coef: 0.4783 - iou: 0.3450\n",
      "Epoch 7: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 242s 685ms/step - loss: 0.5211 - acc: 0.9832 - dice_coef: 0.4783 - iou: 0.3450 - val_loss: 0.5622 - val_acc: 0.9872 - val_dice_coef: 0.4378 - val_iou: 0.3139 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.5248 - acc: 0.9835 - dice_coef: 0.4757 - iou: 0.3451\n",
      "Epoch 8: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 243s 689ms/step - loss: 0.5248 - acc: 0.9835 - dice_coef: 0.4757 - iou: 0.3451 - val_loss: 0.6056 - val_acc: 0.9848 - val_dice_coef: 0.3944 - val_iou: 0.2842 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.4865 - acc: 0.9834 - dice_coef: 0.5120 - iou: 0.3824\n",
      "Epoch 9: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 244s 692ms/step - loss: 0.4865 - acc: 0.9834 - dice_coef: 0.5120 - iou: 0.3824 - val_loss: 0.7183 - val_acc: 0.9844 - val_dice_coef: 0.2817 - val_iou: 0.2010 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.4818 - acc: 0.9846 - dice_coef: 0.5186 - iou: 0.3823\n",
      "Epoch 10: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "352/352 [==============================] - 242s 688ms/step - loss: 0.4818 - acc: 0.9846 - dice_coef: 0.5186 - iou: 0.3823 - val_loss: 0.8110 - val_acc: 0.9828 - val_dice_coef: 0.1890 - val_iou: 0.1406 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.4702 - acc: 0.9865 - dice_coef: 0.5314 - iou: 0.4010\n",
      "Epoch 11: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 242s 686ms/step - loss: 0.4702 - acc: 0.9865 - dice_coef: 0.5314 - iou: 0.4010 - val_loss: 0.5408 - val_acc: 0.9867 - val_dice_coef: 0.4592 - val_iou: 0.3447 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.4420 - acc: 0.9861 - dice_coef: 0.5585 - iou: 0.4251\n",
      "Epoch 12: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 244s 691ms/step - loss: 0.4420 - acc: 0.9861 - dice_coef: 0.5585 - iou: 0.4251 - val_loss: 0.5265 - val_acc: 0.9869 - val_dice_coef: 0.4735 - val_iou: 0.3509 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.4336 - acc: 0.9869 - dice_coef: 0.5657 - iou: 0.4330\n",
      "Epoch 13: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 243s 688ms/step - loss: 0.4336 - acc: 0.9869 - dice_coef: 0.5657 - iou: 0.4330 - val_loss: 0.5081 - val_acc: 0.9868 - val_dice_coef: 0.4919 - val_iou: 0.3653 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.4368 - acc: 0.9866 - dice_coef: 0.5636 - iou: 0.4316\n",
      "Epoch 14: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 242s 687ms/step - loss: 0.4368 - acc: 0.9866 - dice_coef: 0.5636 - iou: 0.4316 - val_loss: 0.4908 - val_acc: 0.9884 - val_dice_coef: 0.5092 - val_iou: 0.3850 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.4338 - acc: 0.9861 - dice_coef: 0.5673 - iou: 0.4385\n",
      "Epoch 15: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 242s 687ms/step - loss: 0.4338 - acc: 0.9861 - dice_coef: 0.5673 - iou: 0.4385 - val_loss: 0.5299 - val_acc: 0.9875 - val_dice_coef: 0.4701 - val_iou: 0.3538 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.4205 - acc: 0.9874 - dice_coef: 0.5792 - iou: 0.4496\n",
      "Epoch 16: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 244s 693ms/step - loss: 0.4205 - acc: 0.9874 - dice_coef: 0.5792 - iou: 0.4496 - val_loss: 0.5086 - val_acc: 0.9877 - val_dice_coef: 0.4914 - val_iou: 0.3728 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.4246 - acc: 0.9874 - dice_coef: 0.5742 - iou: 0.4438\n",
      "Epoch 17: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "352/352 [==============================] - 244s 691ms/step - loss: 0.4246 - acc: 0.9874 - dice_coef: 0.5742 - iou: 0.4438 - val_loss: 0.5176 - val_acc: 0.9878 - val_dice_coef: 0.4824 - val_iou: 0.3749 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.4129 - acc: 0.9873 - dice_coef: 0.5874 - iou: 0.4544\n",
      "Epoch 18: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 240s 681ms/step - loss: 0.4129 - acc: 0.9873 - dice_coef: 0.5874 - iou: 0.4544 - val_loss: 0.5003 - val_acc: 0.9879 - val_dice_coef: 0.4997 - val_iou: 0.3759 - lr: 1.0000e-06\n",
      "Epoch 19/100\n",
      "353/352 [==============================] - ETA: 0s - loss: 0.4088 - acc: 0.9879 - dice_coef: 0.5911 - iou: 0.4584\n",
      "Epoch 19: saving model to files_mass_seg_xval\\unet_mass_seg_v009_5.hdf5\n",
      "352/352 [==============================] - 244s 691ms/step - loss: 0.4088 - acc: 0.9879 - dice_coef: 0.5911 - iou: 0.4584 - val_loss: 0.5695 - val_acc: 0.9874 - val_dice_coef: 0.4305 - val_iou: 0.3130 - lr: 1.0000e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22fa7b41be0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "\n",
    "#Data augmentation\n",
    "data_gen_args = dict(rotation_range=90,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    fill_mode='wrap')\n",
    "\n",
    "# SETTINGS ***\n",
    "batch_size=2\n",
    "learning_rate=1e-4\n",
    "\n",
    "train_gen = trainGenerator(batch_size,'mass_seg_08/train0'+vid[-1],'mg','mask',data_gen_args,save_to_dir = None)\n",
    "valid_gen = trainGenerator(batch_size,'mass_seg_08/valid0'+vid[-1],'mg','mask',data_gen_args,save_to_dir = None)\n",
    "\n",
    "# train_count images are used for training, valid_count images for validating\n",
    "train_steps = train_count//batch_size\n",
    "valid_steps = valid_count//batch_size\n",
    "\n",
    "# SETTINGS ***\n",
    "loss=dice_loss\n",
    "steps_per_epoch=2.5*train_steps\n",
    "num_epochs=100\n",
    "\n",
    "model = build_resnet50_unet()\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate)\n",
    "metrics = [\"acc\", dice_coef, iou]\n",
    "model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "\n",
    "callbacks = [\n",
    "             ModelCheckpoint('files_mass_seg_xval/unet_mass_seg_'+vid+'.hdf5', verbose=1, save_best_model=True),\n",
    "             ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-8),\n",
    "             CSVLogger(\"files_mass_seg_xval/data_\"+vid+\".csv\"),\n",
    "             EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n",
    "            ]\n",
    "\n",
    "model.fit(train_gen, validation_data=valid_gen, steps_per_epoch=steps_per_epoch, validation_steps=valid_steps, \n",
    "                    epochs=num_epochs, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate your model and save predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 16s 239ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\1_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\3_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\4_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\5_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\9_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\10_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\11_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\14_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\23_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\28_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\30_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\31_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\32_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\35_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\37_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\41_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\42_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\43_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\46_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\48_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\49_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\53_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\54_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\55_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\57_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\59_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\60_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n",
      "D:\\research\\breastCancer\\mass_seg\\codes\\data.py:110: UserWarning: mass_seg_08/valid05/pred\\62_predict_v009.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict_%s.png\"%(i,vid)),img)\n"
     ]
    }
   ],
   "source": [
    "validGene = testGenerator(\"mass_seg_08/valid0\"+vid[-1]+\"/pred\",num_image=valid_count)\n",
    "model.load_weights(\"files_mass_seg_xval/unet_mass_seg_\"+vid+\".hdf5\")\n",
    "results = model.predict(validGene,valid_count,verbose=1)\n",
    "saveResult(\"mass_seg_08/valid0\"+vid[-1]+\"/pred\",results,vid[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-tf22",
   "language": "python",
   "name": "tf-gpu22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
